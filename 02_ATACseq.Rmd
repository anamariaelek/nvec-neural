---
title: "ATACseq"
output:
  html_document:
    self_contained: true
    toc: true
    toc_float: true
    toc-location: left
editor: visual
---

## Setup

Load packages

```{r warning=FALSE, message=FALSE, results = FALSE}
library(data.table)
library(stringr)
library(ggplot2)
theme_py <- theme_light() + theme(
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.border = element_rect(colour = "black", fill = NA),
  text = element_text(size=20),
  strip.placement = "outside", 
  strip.text = element_text(size=20, color="black"),
  strip.background = element_rect(fill="white")
)
theme_set(theme_py)
library(patchwork)
library(ggrepel)
library(ComplexHeatmap)
library(DESeq2)
library(consensusSeekeR)
library(BSgenome.jaNemVect1.1.DToL.Assembly)
library(GenomicRanges)
library(parallel)
library(universalmotif)
source("../motif-analysis/mta_downstream_functions.R")
```

Directories

```{r}
dat_dir <- "ATACSEQ/nucleosome_free_regions/"
pks_dir <- file.path(dat_dir, "macs2_peaks")
cns_dir <- file.path(dat_dir, "consensus_peaks")
hom_dir <- file.path(dat_dir, "homer")
res_dir <- file.path(dat_dir, "results")
fig_dir <- file.path(dat_dir, "plots")
for (newdir in c(cns_dir, hom_dir, res_dir, fig_dir))
  dir.create(newdir, showWarnings = FALSE)
```

## Peaks counts

Find consensus set of peaks

```{r eval=FALSE}
require(consensusSeekeR)
require(BSgenome.jaNemVect1.1.DToL.Assembly)
require(parallel)

# load peaks
pks_files <- list.files(pks_dir, pattern="narrowPeak", recursive=FALSE, full.names=TRUE)
names(pks_files) <- str_remove(basename(pks_files), ".mLb.clN.ncfree_peaks.narrowPeak")
nP_list <- lapply(names(pks_files), function(x) {
    nP <- readNarrowPeakFile(pks_files[x], extractRegions = TRUE, extractPeaks = TRUE)
    names(nP$narrowPeak) <- rep(x, length(nP$narrowPeak))
    names(nP$peak) <- rep(x, length(nP$peak))
    nP
})
regions <- GenomicRanges::GRangesList(lapply(nP_list, function(x) x$narrowPeak))
peaks <- GenomicRanges::GRangesList(lapply(nP_list, function(x) x$peak))
names(regions) <- names(pks_files)
names(peaks) <- names(pks_files)

# get consensus
chrList <- Seqinfo(
    seqnames = seqnames(BSgenome.jaNemVect1.1.DToL.Assembly),
    seqlengths = seqlengths(BSgenome.jaNemVect1.1.DToL.Assembly),
    isCircular = c(rep(FALSE, length(seqnames(BSgenome.jaNemVect1.1.DToL.Assembly))-1), TRUE),
    genome = "jaNemVect1.1"
)
message(Sys.time(), " Started calculating consensus")
ur <- unlist(regions)
up <- unlist(peaks)

# debugging
# id <- seqnames(ur)=="NC_064035.1" & start(ur)>1644829 & end(ur)<1649211
# ur <- ur[id]
# up <- up[id]
# chrList <- chrList["NC_064035.1"]

results <- findConsensusPeakRegions(
    narrowPeaks = ur,
    peaks = up,
    chrInfo = chrList,
    extendingSize = 250,
    expandToFitPeakRegion = FALSE,
    shrinkToFitPeakRegion = FALSE,
    minNbrExp = 2,
    nbrThreads = detectCores()-1
)
message(Sys.time(), " Done calculating consensus")
saveRDS(results, file.path(cns_dir,"consensusSeekeR-results.RDS"))

# resize peaks
pks_cns <- results$consensusRanges
pks_mid <- start(pks_cns) + (end(pks_cns)-start(pks_cns))/2
ranges(pks_cns) <- IRanges(pks_mid,width=0)
pks_scl <- promoters(pks_cns, upstream=125, downstream=125)

# trim out-of-bound peaks
seqlengths(pks_scl) <- seqlengths(BSgenome.jaNemVect1.1.DToL.Assembly)[names(seqlengths(pks_scl))]
pks_scl <- trim(pks_scl)

# save bed file
pks_bed <- as.data.table(pks_scl)
pks_bed[,name:=paste0("peak",1:.N)]
pks_bed[,width:=NULL][,score:="."]
setcolorder(pks_bed, c("seqnames","start","end","name","score","strand"))
fwrite(pks_bed, file.path(cns_dir,"consensusSeekeR-peaks.bed"), sep="\t", col.names=FALSE)
```

Get scores for consensus peaks in all samples.

```{r include=FALSE, eval=FALSE}
# load consensus peaks
pks_bed <- fread(file.path(cns_dir,"consensusSeekeR-peaks.bed"))
setnames(pks_bed, c("seqnames", "start", "end", "name", "score", "strand"))
pks_grn <- makeGRangesFromDataFrame(pks_bed, keep.extra.columns = TRUE)

# get counts in consensus peaks
bws_files <- list.files(file.path(dat_dir, "bigwig"), pattern = ".bigwig", full.names = TRUE)
bws_names <- str_remove(basename(bws_files),".mLb.clN.ncfree.bigwig")
names(bws_files) <- bws_names
bws_signal <- rbindlist(lapply(bws_names, function(smp){
  as.data.table(import(bws_files[smp]))[,sample:=smp][]
}))

# overlap signal with consensus peaks
pks_list <- lapply(bws_names, function(smp) {
  bw_dt <- bws_signal[sample==smp]
  bw_gr <- makeGRangesFromDataFrame(bw_dt, keep.extra.columns = TRUE)
  # ovl
  ovl <- findOverlaps(query = bw_gr, subject = pks_grn)
  ps_dt <- as.data.table(pks_grn[subjectHits(ovl)])
  scs <- mcols(bw_gr[queryHits(ovl)])$score
  ps_dt[,score:=scs]
  # non ovl
  if (any(!pks_grn$name %in% ps_dt$name)) {
    message("Adding missing peks for ", smp)
    ps_dt <- rbindlist(list(
      ps_dt,
      as.data.table(pks_grn)[!name %in% ps_dt$name][,score:=0]
    ), use.names = TRUE)
  }
  ps_dt[,sample:=smp][]
})
pks_dt <- rbindlist(pks_list)

# keep max signal in each peak
pks_dt[,score:=as.numeric(score)]
pkt_dt <- pks_dt[order(name,-score)][,.SD[1],.(name,sample)]
pkt_dt[,seqnames:=factor(seqnames, levels=levels(seqnames(pks_grn)))]
setorder(pkt_dt, seqnames, start, end)

# save bed file
pkt_dt[,width:=NULL]
setcolorder(pkt_dt, c("seqnames", "start", "end", "name", "score", "strand", "sample"))
fwrite(pkt_dt, file.path(cns_dir,"consensusSeekeR-peaks-samples.bed"), sep="\t", col.names=FALSE)
```

```{bash eval=FALSE}
nth=12
res="ATACSEQ/nucleosome_free_regions/consensus_peaks/consensusSeekeR-peaks-counts.tsv"
bed="ATACSEQ/nucleosome_free_regions/consensus_peaks/consensusSeekeR-peaks.bed"
bam=$( echo ATACSEQ/nucleosome_free_regions/bam/*R*bam )

cols=$( echo -e seqnames start end name score strand | column -t )
for b in $bam
do 
  echo $b
  name=$( basename $b)
  cols=$( echo -e ${cols} ${name} | column -t )
done

echo -e ${cols} > ${res%%tsv}txt
bedtools multicov -bams ${bam} -bed ${bed} > ${res}
```

Data for differential peaks analysis

```{r}
# load counts in peaks
pks_ct <- fread(file.path(cns_dir, "consensusSeekeR-peaks-counts.tsv"), header=FALSE)
colnames <- readLines(file.path(cns_dir, "consensusSeekeR-peaks-counts.txt"), n=1)
colnames <- str_remove_all(colnames, ".mLb.clN.ncfree.sorted.bam")
colnames <- str_split(colnames, " ")[[1]]
colnames(pks_ct) <- colnames

# column data
condition_cols <- c("positive"="blue","negative"="red") 
line_cols = c("Elav" = "#ff7f00", "Fox" = "#984ea3", "Ncol" = "#4daf4a")

col_dt <- data.table(sample=colnames(pks_ct)[7:28])
col_dt[,reporterline:=str_extract(sample,"Elav|Fox|Ncol")]
col_dt[,reporterline:=factor(reporterline, levels=c("Elav","Fox","Ncol"))]
col_dt[,condition:=str_extract(sample,"pos|neg")]
col_dt[,condition:=str_replace_all(condition,c("pos"="positive","neg"="negative"))]
col_dt[,condition:=factor(condition, levels = c("negative","positive"))]
col_dt[,group:=paste(as.character(reporterline), as.character(condition), sep=""), by=1:nrow(col_dt)]
col_dt[,group:=factor(group)]

col_df <- copy(col_dt)
class(col_df) <- "data.frame"
rownames(col_df) <- col_df$sample

# counts matrix
pks_mt <- as.matrix(pks_ct[,-c(1:6)])
rownames(pks_mt) <- pks_ct$name
pks_mt <- pks_mt[,rownames(col_df)]

# DESeq2
require(DESeq2)
dds <- DESeqDataSetFromMatrix(
  countData = pks_mt,
  colData = col_df,
  design = ~ condition + reporterline
)
saveRDS(dds, file.path(res_dir, "dds.rds"))
```

Peaks counts distributions

```{r fig.width=8, fig.height=6, warning=FALSE, message=FALSE}
# normalized accessibility distribution
pks_dt <- as.data.table(pks_mt, keep.rownames = "peak")
pks_dt <- melt.data.table(pks_dt, id.vars = "peak", variable.name = "sample", value.name = "norm_counts")
pks_dt <- merge.data.table(pks_dt, col_dt, by="sample")
setorder(pks_dt, peak, condition, reporterline)
pks_dt[,sample:=factor(sample, levels = unique(pks_dt$sample))]

gp_acc <- ggplot(pks_dt, aes(sample, log10(norm_counts), fill=reporterline)) +
  geom_violin(scale = "width", alpha = 0.8, color = "black") +
  geom_boxplot(width = 0.5, outlier.shape = NA, alpha = 0.8, color = "black") + 
  scale_fill_manual(values = line_cols, limits = force) +
  scale_y_continuous(expand = expansion(mult = c(0,0.01))) +
  labs(x="samples", y="peak\naccessibility") +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
    legend.title = element_blank(), legend.position = "none"
  )

var_dt <- pks_dt[,.(var=var(norm_counts)),.(peak)]
gp_var <- ggplot(var_dt, aes(log10(var))) + 
  geom_density() +
  scale_x_continuous(limits=c(-4,NA)) +
  scale_y_continuous(expand = expansion(mult = c(0,0.01))) +
  labs(x = "log10(accessibility variance)")

gp_pch <- gp_acc / gp_var + plot_layout(heights = c(2,1))
gp_pch
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "peaks_var_norm.pdf"), width=8, height=6)
gp_pch
dev.off()
```

Use normalized log-transformed accessibility data

```{r}
# normalize samples
dds <- readRDS(file.path(res_dir, "dds.rds"))
dds <- estimateSizeFactors(dds)
norm_mt <- counts(dds, normalized=TRUE)
# row normalize to bring peaks to same range
norm_mt <- (norm_mt+10)/apply(norm_mt+10,1,median) 
norm_mt <- log2(norm_mt)
# save
write.table(norm_mt, file.path(res_dir,"norm_accessibility.tsv"), sep="\t", row.names = TRUE, quote = FALSE)
```

## PCA

PCA on all samples.

```{r fig.width=8, fig.height=10, warning=FALSE}
set.seed(1950)
pca_res <- prcomp(t(norm_mt), center = TRUE)

# variance explained
pca_var <- data.table(pct_var = round(((pca_res$sdev) ^ 2 / sum((pca_res$sdev) ^ 2)* 100), 2))
pca_var[,pct_cum:=cumsum(pct_var)]
pca_var[,PC:=factor(1:.N)]
gp_var <- ggplot(pca_var, aes(PC, pct_var)) + 
  geom_bar(stat = "identity") +
  geom_line(aes(y = pct_cum, group = 1)) + 
  geom_point(aes(y = pct_cum)) +
  scale_y_continuous(expand = expansion(0.01,0)) +
  labs(y = "% of variance\nexplained", x = "PC") +
  theme(panel.grid.major.y = element_line(size = 0.5))

pca_dt <- as.data.table(pca_res$x, keep.rownames = "sample")
pca_dt <- merge.data.table(col_dt, pca_dt, by="sample", sort=FALSE)
gp_bip <- ggplot(pca_dt, aes(PC1, PC2, fill=reporterline, shape=condition)) + 
  geom_point(size=5) +
  scale_fill_manual(values = line_cols) +
  scale_shape_manual(values = c("positive" = 21, "negative" = 24)) +
  guides(fill = guide_legend(override.aes=list(shape=21))) +
  geom_text_repel(aes(label = sample))

gp_pch <- gp_var / gp_bip 
gp_pch
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "PCA_all.pdf"), width=8, height=10)
gp_pch
dev.off()
```

PCA per cell line

```{r fig.height=8, fig.width=7}
set.seed(1950)

gp_l <- lapply(names(line_cols), function(cl) {
  
  pca_res <- prcomp(t(norm_mt[,grep(cl,colnames(norm_mt))]), center = TRUE)
  
  # variance explained
  pca_var <- data.table(pct_var = round(((pca_res$sdev) ^ 2 / sum((pca_res$sdev) ^ 2)* 100), 2))
  pca_var <- pca_var[-nrow(pca_var)]
  pca_var[,pct_cum:=cumsum(pct_var)]
  pca_var[,PC:=factor(1:.N-1)]
  gp_var <- ggplot(pca_var, aes(PC, pct_var)) + 
    geom_bar(stat = "identity") +
    geom_line(aes(y = pct_cum, group = 1)) + 
    geom_point(aes(y = pct_cum)) +
    scale_y_continuous(expand = expansion(0.01,0)) +
    labs(y = "% of variance\nexplained", x = "PC") +
    theme(panel.grid.major.y = element_line(size = 0.5))
  
  # pca plot
  pca_dt <- as.data.table(pca_res$x, keep.rownames = "sample")
  pca_dt <- merge.data.table(col_dt, pca_dt, by="sample", sort=FALSE)
  gp_bip <- ggplot(pca_dt, aes(PC1, PC2, fill=condition, shape=condition)) + 
    geom_point(size=5) +
    scale_shape_manual(values = c("positive" = 21, "negative" = 24)) +
    scale_fill_manual(values = condition_cols) +
    guides(fill = guide_legend(override.aes=list(shape=21))) +
    geom_text_repel(aes(label = sample))
  
  gp_var / gp_bip 

})
gp_l
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "PCA_reporter_lines.pdf"), width=7, height=8)
gp_l
dev.off()
```

## Marker peaks

Use normalized peak counts

```{r}
norm_mt <- read.table(file.path(res_dir,"norm_accessibility.tsv"), header = TRUE)
```

Identify marker peaks

```{r include=FALSE, eval=TRUE}
# peak markers by normalized accessibility
peaks_fc <- names(which(apply(norm_mt, 1, function(x) sort(x,decreasing=TRUE)[2])>=2))
peaks_vari <- names(which(apply(norm_mt, 1, function(x) var(x)>1)))
peaks_marks_1 <- intersect(peaks_fc, peaks_vari)
length(peaks_marks_1)
```

```{r include=TRUE, eval=TRUE}
# gene markers by high FC + significant DEseq2 LTR test 
dds <- readRDS(file.path(res_dir, "dds.rds"))
dds <- DESeq(dds, test="LRT", reduced=~1)
dds_res <- results(dds)
dds_qval <- dds_res$padj 
names(dds_qval) <- rownames(dds_res)
peaks_deseq <- names(which(dds_qval<1e-2))
peaks_high <- names(which(apply(norm_mt, 1, function(x) sort(x,decreasing = T)[2])>=1.8))
peaks_marks <- intersect(peaks_high, peaks_deseq)
length(peaks_marks)
```

Cluster peaks

```{r fig.width=10, fig.height=6}
set.seed(1950)

# determine k for kmeans
ks <- 1:30
tot_withinss <- sapply(ks,  function(k) {
  cl <- kmeans(norm_mt[peaks_marks,], k)
  cl$tot.withinss
})
elbow_dt <- data.table(k = ks, tot_withinss = tot_withinss)
elbow_gp <- ggplot(elbow_dt, aes(x = k, y = tot_withinss)) +
  geom_line() + geom_point()+
  scale_x_continuous(breaks = ks)
elbow_gp
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "kmeans_elbow.pdf"), width=8, height=6)
elbow_gp
dev.off()
```

Cluster peaks

```{r}
# kmeans
set.seed(1950)
k <- 19
cl <- kmeans(norm_mt[peaks_marks,], k)
peaks_order_list <- tapply(names(cl$cluster), cl$cluster, function(gs) {
  cor_peaks <- cor(t(norm_mt[gs,]))
  hclust_peaks <- hclust(as.dist(1-cor(cor_peaks)),method="ward.D2")
  rownames(cor_peaks)[hclust_peaks$order]
})
names(peaks_order_list) <- unique(cl$cluster)
peaks_order_list <- peaks_order_list[as.character(seq_along(peaks_order_list))]

# cluster clusters
cluster_order <- hclust(dist(cor(t(cl$centers)),method="euclidean"),method="ward.D2")$order
peaks_order_list <- peaks_order_list[as.character(cluster_order)]
peaks_order <- unname(unlist(peaks_order_list))
clusters_dt <- data.table(
  peak = peaks_order,
  clusters = as.character(rep(names(peaks_order_list), sapply(peaks_order_list, length)))
)

# group clusters (manually)
clusters_dt[clusters %in% c(16), group:=1] # Elav
clusters_dt[clusters %in% c(5), group:=2] # Elav + Fox
clusters_dt[clusters %in% c(14,17), group:=3] # Fox
clusters_dt[clusters %in% c(6,11), group:=4] # Fox + Ncol
clusters_dt[clusters %in% c(9), group:=5] 
clusters_dt[clusters %in% c(13,4), group:=6] # Elav + Ncol
clusters_dt[clusters %in% c(1,2,15,7,8,10,19,18), group:=7] # Ncol
clusters_dt[clusters %in% c(12), group:=8] 
clusters_dt[clusters %in% c(3), group:=9] 
setorder(clusters_dt, group)
peaks_order <- clusters_dt$peak

# add clusters info to peaks coordinates bed file
pks_bed <- fread(file.path(cns_dir,"consensusSeekeR-peaks.bed"))
setnames(pks_bed, c("V4"), c("peak"))
clusters_bed <- merge.data.table(pks_bed, clusters_dt, by="peak", sort = FALSE)
setcolorder(clusters_bed, c(colnames(pks_bed)))
clusters_bed[,clusters:=paste0("C",clusters)]
clusters_bed[,group:=paste0("G",group)]
fwrite(clusters_bed, file.path(res_dir, "consensusSeekeR-peaks-clusters.bed"), sep="\t", col.names = FALSE)
```

Heatmap of markers

```{r fig.height=10, fig.width=8, warning=FALSE, message=FALSE}
# order rows and columns
samples_order <- col_dt[order(condition,reporterline)]$sample
plot_mt <- norm_mt[peaks_order,samples_order]

# center at 0
plot_min <- quantile(abs(range(plot_mt)),0.75)
plot_min <- 5
plot_mt <- pmin(pmax(plot_mt,-plot_min),plot_min) 

# heatmap colors
col_vec <- colorRampPalette(RColorBrewer::brewer.pal(11,'BrBG'))(1000)
col_fun <- circlize::colorRamp2(seq(-plot_min, plot_min, length.out = length(col_vec)), col_vec)

# color annotaitons
col_ann <- HeatmapAnnotation(
    which = "column", border = TRUE,
    "reporterline" = as.character(col_dt[match(colnames(plot_mt),sample)]$reporterline),
    "condition" = as.character(col_dt[match(colnames(plot_mt),sample)]$condition), 
    col = list("reporterline" = line_cols, "condition" = condition_cols)
)

# # peak module annotations (clusters)
# clann <- clusters_dt[match(rownames(plot_mt),peak)]$clusters
# clann_lab <- unique(clusters_dt[match(rownames(plot_mt),peak)]$clusters)
# clann <- factor(clann, levels=clann_lab)
# module_ann <- HeatmapAnnotation(
#     which = "row", border = TRUE,
#     "cluster" = anno_block(
#       labels = clann_lab,
#       gp = gpar(col=NA)
#     )
# )
# row_split <- clann

# peak module annotations (manually groupped clusters)
grann <- clusters_dt[match(rownames(plot_mt),peak)]$group
grann_lab <- unique(clusters_dt[match(rownames(plot_mt),peak)]$group)
grann <- factor(grann, levels=grann_lab)
module_ann <- HeatmapAnnotation(
    which = "row", border = TRUE,
    "group" = anno_block(
      labels = grann_lab,
      gp = gpar(col=NA)
    )
)
row_split <- grann


# peaks annotations
row_labels_marks_ids <- match(clusters_dt[,.SD[1],clusters]$peak, rownames(plot_mt))
row_labels_marks <- clusters_dt[,.SD[1],clusters]$clusters
mark_ann <- HeatmapAnnotation(
  which = "row", 
  marker = anno_mark(at = row_labels_marks_ids, labels = row_labels_marks),
  show_legend = FALSE
)
mark_ann <- HeatmapAnnotation(
    which = "row", border = TRUE,
    "padj<0.05" = rownames(plot_mt) %in% peaks_deseq,
    "var>1" = rownames(plot_mt) %in% peaks_vari,
    "FC>2" = rownames(plot_mt) %in% peaks_fc,
    col = list(
      "padj<0.05" = c("TRUE" = "#e6ab02", "FALSE"="#d9d9d9"),
      "var>1" = c("TRUE" = "#3690c0", "FALSE"="#d9d9d9"),
      "FC>2" = c("TRUE" = "#e7298a", "FALSE"="#d9d9d9")
    )
)

# heatmap
hm <- Heatmap(
  plot_mt, name = "normalized\naccessibility",
  col = col_fun,
  cluster_rows = FALSE, cluster_columns = FALSE,
  show_row_names = FALSE, show_column_names = TRUE,
  row_title = "peaks", 
  row_split = row_split, 
  cluster_row_slices = FALSE,
  top_annotation = col_ann,  
  left_annotation = module_ann, right_annotation = mark_ann,
  border = TRUE
)
hm
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "peaks_heatmap_group.pdf"), width=8, height=10)
draw(hm)
dev.off()
```

## Differntial peak analysis

Differential analysis with DESeq2

```{r, eval=TRUE}
# all positive vs negative
dds_cond <- DESeqDataSetFromMatrix(
  countData = pks_mt,
  colData = col_df,
  design = ~ condition
)
dds_cond <- DESeq(dds_cond)

# condition within reporter line line
dds_conl <- DESeqDataSetFromMatrix(
  countData = pks_mt,
  colData = col_df,
  design = ~ group
)
dds_conl <- DESeq(dds_conl)

```

Function for MA plots

```{r}
ggplotMA <- function(res, padj_thr=0.05,sign_col="red",lims_fc=c(NA,NA),lims_mean=c(NA,NA),title="") {
  res_dt <- as.data.table(res)
  res_dt[log2FoldChange<lims_fc[1], log2FoldChange:=lims_fc[1]]
  res_dt[log2FoldChange>lims_fc[2], log2FoldChange:=lims_fc[2]]
  gp <- ggplot(res_dt, aes(x=baseMean, y=log2FoldChange, colour=padj<padj_thr)) + 
    geom_point(size=0.5) + 
    scale_color_manual(values = c("FALSE"="grey", "TRUE"=sign_col), name = sprintf("p.adjusted < %s",padj_thr)) +
    guides(colour = guide_legend(override.aes = list(size=4))) +
    scale_y_continuous(limits = lims_fc, expand = expansion(mult = c(0.01,0.01))) +
    scale_x_continuous(limits = lims_mean) +
    geom_hline(aes(yintercept = 0), size = 1) +
    labs(
      x = "mean of normalized counts",
      y = "log2 fold change", 
      subtitle = sprintf(
        "up=%s; down=%s",
        nrow(res_dt[padj<padj_thr & log2FoldChange>0]),
        nrow(res_dt[padj<padj_thr & log2FoldChange<0])
      )
    ) +
    theme(
      legend.position = "bottom", 
      plot.title = element_text(size = 20),
      plot.subtitle = element_text(size = 18)
    )
  if (title!="")
    gp <- gp + labs(title = title)
  gp
}
```

Contrasts

```{r message=FALSE, warning=FALSE, fig.width=8, fig.height=9}
contrast <- c("condition","positive","negative")
res_pos <- results(dds_cond, contrast = contrast)
res_lfc_pos <- lfcShrink(dds_cond, contrast = contrast, type="ashr")
gp_pos <- ggplotMA(
  res_lfc_pos, 
  lims_fc=c(-3,3), lims_mean=c(NA,1e3),
  title=sprintf("%s vs %s",contrast[2],contrast[3])
)

contrast <- c("group", "Foxpositive", "Foxnegative")
res_fox <- results(dds_conl, contrast = contrast)
res_lfc_fox <- lfcShrink(dds_conl, contrast = contrast, type="ashr")
contrast <- str_replace_all(contrast,c("positive"=" positive","negative"=" negative"))
gp_fox <- ggplotMA(
  res_lfc_fox, 
  lims_fc=c(-3,3), lims_mean=c(NA,1e3),
  title=sprintf("%s vs %s",contrast[2],contrast[3])
)

contrast <- c("group", "Elavpositive", "Elavnegative")
res_elav <- results(dds_conl, contrast = contrast)
res_lfc_elav <- lfcShrink(dds_conl, contrast = contrast, type="ashr")
contrast <- str_replace_all(contrast,c("positive"=" positive","negative"=" negative"))
gp_elav <- ggplotMA(
  res_lfc_elav, 
  lims_fc=c(-3,3), lims_mean=c(NA,1e3),
  title=sprintf("%s vs %s",contrast[2],contrast[3])
)

contrast <- c("group", "Ncolpositive", "Ncolnegative")
res_ncol <- results(dds_conl, contrast = contrast)
res_lfc_ncol <- lfcShrink(dds_conl, contrast = contrast, type="ashr")
contrast <- str_replace_all(contrast,c("positive"=" positive","negative"=" negative"))
gp_ncol <- ggplotMA(
  res_lfc_ncol, 
  lims_fc=c(-3,3), lims_mean=c(NA,1e3),
  title=sprintf("%s vs %s",contrast[2],contrast[3])
)

gp_pch <- ((gp_pos + gp_fox) / (gp_elav + gp_ncol)) + 
  plot_layout(guides = "collect") & theme(legend.position = "bottom")
gp_pch
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "MA_plots.pdf"), width=8, height=9)
gp_pch
dev.off()
```

## Motif discovery

Save per-group foreground and background peaks for motif discovery

```{r eval=FALSE}
dir.create(file.path(hom_dir, "peaks"))
dir.create(file.path(hom_dir, "results"))
clusters_bed <- fread(file.path(res_dir, "consensusSeekeR-peaks-clusters.bed"))
setnames(clusters_bed, c("seqnames","start","end","name","score","strand","cluster","group"))
clusters_bed[,group:=factor(group, levels=paste0("G",seq_along(unique(group))))]
for (ci in levels(clusters_bed$group)) {
    fg <- clusters_bed[group==ci]
    bg <- clusters_bed[group!=ci]
    fwrite(fg, file.path(hom_dir, "peaks",sprintf("peaks-%s-fg.bed",ci)), col.names=FALSE, sep="\t")
    fwrite(bg, file.path(hom_dir, "peaks",sprintf("peaks-%s-bg.bed",ci)), col.names=FALSE, sep="\t")
}
```

De novo and known motifs in groups of accessible peaks

```{bash eval=FALSE}

findMotifs(){
    genome="genome/Nvec_vc1.1_gDNA.fasta"
    homdir="ATACSEQ/nucleosome_free_regions/homer"
    bedfg=${homdir}"/peaks/peaks-G"${1}"-fg.bed"
    bedbg=${homdir}"/peaks/peaks-G"${1}"-bg.bed"
    outdir=$homdir"/results/G${1}-Homer"
    echo ""
    echo "Starting HOMER analysis for" $1
    echo "using the intervals in" $bedfg
    echo "Output will be saved to" $outdir
    findMotifsGenome.pl $bedfg $genome $outdir -size 250 -len 6,8,10,12 -bg $bedbg 
    echo ""
    echo "Finished de novo analysis for module" $1
}

for cluster in {1..9}
do
findMotifs "$cluster" &
    done
wait
echo "Done."

```

Parse de novo Homer results

```{bash eval=FALSE}
dir="./ATACSEQ/nucleosome_free_regions/homer/results/"
modules=$( find ${dir} -maxdepth 2 -iname "*-Homer" -printf "%f\n" )
for i in $modules
do 
  less ${dir}/${i}/homerMotifs.all.motifs | grep ">" > tmp.txt
  awk -v m="$M" 'BEGIN {FS="\t"} {OFS="\t"} {print m, $0}' tmp.txt >> ${dir}/${i}/homerResults.txt
done
```

Parse all Homer results

```{r eval=FALSE}
clusters_bed <- fread(file.path(res_dir, "consensusSeekeR-peaks-clusters.bed"))
setnames(
  clusters_bed, 
  c("seqnames", "start", "end", "name", "score", "strand", "cluster", "group")
)
clusters_bed[,group:=factor(group, levels=paste0("G",seq_along(unique(group))))]

ParseHomerDenovo <- function(fn, eta=1) {
  
  # parse homerResults.txt
  dt <- fread(fn, sep="\t", header=FALSE)[,-1]
  setnames(dt,c("consensus","name","logodds_threshold","logpval","0","occurence","stats"))
  dt[,consensus:=stringr::str_remove(consensus,">")]
  dt[,c("fg","bg","pval"):=tstrsplit(occurence,",")]
  dt_occurence <- dt[,lapply(.SD,stringr::str_remove,pattern="[TBP]:"),.SDcols=c("fg","bg","pval")]
  dt_perc <- dt_occurence[,lapply(.SD,function(x) as.numeric(stringr::str_extract(x,"(?<=\\()\\d+\\.*\\d+"))/100),.SDcols=c("fg","bg")]
  setnames(dt_perc,c("fg","bg"),c("fg_perc","bg_perc"))
  dt_counts <- dt_occurence[,lapply(.SD,function(x) as.numeric(stringr::str_extract(x,"\\d+\\.*\\d*"))),.SDcols=c("fg","bg")]
  setnames(dt_counts,c("fg","bg"),c("fg_count","bg_count"))
  dt_occurence[,c("fg","bg"):=NULL]
  dt_occurence[,pval:=as.numeric(pval)]
  dt[,c("fg","bg","pval","occurence"):=NULL]
  dt <- cbind(dt,dt_perc,dt_counts,dt_occurence)
  dt$qval <- p.adjust(dt$pval, method = "BH")
  dt[,fc:=(fg_count+eta)/(bg_count+eta)]
  
  # parse homerResults folder to get names of best hits for denovo motifs
  hd <- str_remove(fn, ".txt")
  ms <- list.files(hd, pattern = "motif\\d+.motif", full.names=TRUE)
  ml <- lapply(ms, function(x) {
    m <- universalmotif::read_homer(x)
    m@name
  })
  ml <- unlist(unname(ml))
  names(ml) <- str_extract(ml, ".+(?=\\,BestGuess)")
  names(ml) <- ml
  dt[,name2:=ml[name]]
  dt[!is.na(name2), name:=name2]
  dt[,name2:=NULL]
  
  # return
  dt[,.(name,consensus,fc,pval,logpval,qval,fg_count,fg_perc,bg_count,bg_perc)]
}

ParseHomerKnown <- function(fn, eta=1) {
  dt <- fread(fn)
  setnames(dt, c("name","consensus","pval","logpval","qval","fg_count","fg_perc","bg_count","bg_perc"))
  dt[,fg_perc:=as.numeric(stringr::str_remove(fg_perc,"\\%"))/100]
  dt[,bg_perc:=as.numeric(stringr::str_remove(bg_perc,"\\%"))/100]
  dt[,fc:=(fg_count+eta)/(bg_count+eta)]
  dt[,.(name,consensus,fc,pval,logpval,qval,fg_count,fg_perc,bg_count,bg_perc)]
}

hm_list <- lapply(levels(clusters_bed$group), function(ci) {
  dn_fn <- file.path(hom_dir,"results",sprintf("%s-Homer",ci),"homerResults.txt")
  dn_dt <- ParseHomerDenovo(dn_fn)
  kn_fn <- file.path(hom_dir,"results",sprintf("%s-Homer",ci),"knownResults.txt")
  kn_dt <- ParseHomerKnown(kn_fn)
  hm_dt <- rbindlist(list(denovo=dn_dt, known=kn_dt), idcol="set")
  hm_dt
})
names(hm_list) <- levels(clusters_bed$group)
hm_dt <- rbindlist(hm_list, idcol = "group")
fwrite(hm_dt, file.path(hom_dir, "results", "allResuls.txt"), sep="\t", col.names = TRUE)
```

Save all Homer motifs 

```{r eval=FALSE}
mt_dt <- unique(hm_dt[,.(name)])

mt_list <- lapply(levels(clusters_bed$group), function(ci) {
  ci_dir <- file.path(hom_dir,"results",sprintf("%s-Homer",ci))
  ci_mfn <- c(
    list.files(file.path(ci_dir, "homerResults"), pattern = "motif\\d+.motif", full.names=TRUE),
    list.files(file.path(ci_dir, "knownResults"), pattern = "known\\d+.motif", full.names=TRUE)
  )
  ci_mot <- lapply(ci_mfn, universalmotif::read_homer)
  ci_mot
})
names(mt_list) <- levels(clusters_bed$group)

saveRDS(mt_list, file.path(hom_dir,"results","allMotifs.RDS"))
```

Motif enrichment heatmap

```{r fig.height=10, fig.width=6, warning=FALSE, message=FALSE}
dt <- fread(file.path(hom_dir, "results", "allResuls.txt"))

# qvalue
dat_qv <- dcast.data.table(unique(dt[,.(name,group,qval)]), name~group, value.var = "qval")
mat_qv <- data.matrix(dat_qv)[,-1]
mat_qv[is.na(mat_qv)] <- 1
rownames(mat_qv) <- dat_qv$name

# log2fc
dat_fc <- dcast.data.table(unique(dt[,.(name,group,fc)]), name~group, value.var = "fc")
mat_fc <- data.matrix(dat_fc)[,-1]
mat_fc[is.na(mat_fc)] <- 0
rownames(mat_fc) <- dat_fc$name

# convert to numeric (replacing , with .) and multiply with -1 (so that highly significant = higher value)
dt[,minuslog10qval:=-1*log10(qval)]

# filtering
ids <- apply(mat_fc, 1, function(x) max(x)>1) &
  apply(mat_qv, 1, function(x) !is.infinite(min(x)) & !min(x)>0.00001)

# clustering
hc <- hclust(dist(mat_fc[ids,]), method="ward.D2")
ds <- dt[name %in% rownames(mat_fc)[ids]]
ds[,name:=factor(name, levels=rev(rownames(mat_fc)[ids]))]

# ordering
mord <- order(apply(mat_fc[ids,], 1, which.max))
ds[,name:=factor(name, levels=rev(rownames(mat_fc[ids,])[mord]))]

# limit -log10FDR range 
ds[,minuslog10qval:=pmin(minuslog10qval,20)]

# labels
ds[,label:=""]
pattern="hox|pou4|isnm1|neurod1|foxq2d|rfx|pax|islet|ascl"
ds[grep(pattern,name,ignore.case=TRUE),label:=name]
ds[,label_short:=regmatches(label, regexpr(sprintf("(%s)\\d*[A-z]*",pattern), label, ignore.case=TRUE)), by=1:nrow(ds)]

# plot
gp <- ggplot(ds, aes(group, name)) +
  geom_point(aes(size=log(fc+1), color=minuslog10qval)) + 
  geom_text_repel(
    aes(label=ifelse(minuslog10qval>2,label_short,"")),
    color = "black",
    nudge_x = 0.5,
    box.padding = 0.5,
    nudge_y = 1,
    segment.ncp = 3,
    segment.angle = 15
  ) +
  scale_colour_gradientn(colours=c("white","#fee5d9","#fcae91","#fb6a4a","#de2d26","#a50f15")) +
  theme_light() +
  theme(axis.text.y=element_blank(), axis.ticks.y=element_blank())
gp
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "motifs_heatmap_group.pdf"), width=5, height=16)
gp
dev.off()
```

## Motif archetypes

Previously we pulled together Nematostella Direct and Inferred motifs from CisBP, and motifs additionally transferred based on the DBD %ID. We load them now, together with motifs found by Homer, then we do motif clustering and archetyping.

Load Homer motifs

```{r}
# load Homer motifs
data_homer <- fread(file.path(hom_dir, "results","allResuls.txt"))
pwms_homer <- readRDS(file.path(hom_dir,"results","allMotifs.RDS"))
pwms_homer <- unlist(unname(pwms_homer))
names(pwms_homer) <- sapply(pwms_homer, function(x) x@name)
```

Load CisBP Nematostella motifs

```{r eval=FALSE, include=FALSE, echo=FALSE}
# liftover annotation for CisBP motifs
# original in scRNAseq_nvec_v3/TFs/CisBP/Nvec/CisBP_ident_transfered_motifs.RDS
dt_cisbp <- fread(str_replace(pwms_files_cisbp,"RDS","tsv"))
setnames(dt_cisbp, "gene", "ID_JGI_Vienna")
annotation_file <- file.path("annotation","Nvec_annotation_v3_2020-10-23_ID_JGI_Vienna_matched_DToL_names")
dt_ann <- fread(annotation_file)
data_cisbp <- merge.data.table(dt_cisbp, dt_ann, by="ID_JGI_Vienna", all=TRUE)
data_cisbp <- data_cisbp[!is.na(Motif_ID)]
data_cisbp <- data_cisbp[match(names(pwms_cisbp), Motif_ID)]
data_cisbp[is.na(gene), gene:=""]
data_cisbp[is.na(name), name:=""]
setcolorder(
  data_cisbp, c(
    "gene", 
    setdiff(colnames(dt_cisbp),"ID_JGI_Vienna"), 
    "ID_JGI_Vienna","ID_DToL","Percentage_overlap/Blast_ID","Source"
  )
)
setnames(data_cisbp,"gene","Gene_ID")
fwrite(data_cisbp, str_replace(pwms_files_cisbp,"RDS","tsv"), sep="\t")
```

```{r}
# CisBP motifs + additionally transferred based on %ID
pwms_files_cisbp <- file.path("annotation","CisBP_ident_transfered_motifs.RDS")
pwms_cisbp <- readRDS(pwms_files_cisbp) # 2382
data_cisbp <- fread(str_replace(pwms_files_cisbp,"RDS","tsv"))
gen_cisbp <- data_cisbp$Gene_ID
nms_cisbp <- data_cisbp$name
pwms_cisbp_nm <- lapply(seq_along(pwms_cisbp), function(i) {
  motif <- pwms_cisbp[[i]]
  if (!is.na(gen_cisbp[i])) motif@altname <- gen_cisbp[i]
  if (!is.na(nms_cisbp[i])) motif@extrainfo <- nms_cisbp[i]
  return(motif)
})
names(pwms_cisbp_nm) <- names(pwms_cisbp)
```

Save all motifs

```{r}
pwms <- c(pwms_homer,pwms_cisbp)
saveRDS(pwms, file.path(res_dir,"motifs-all.rds"))
```

Parameters for similarity and archetyping

```{r}
# motif similarity
similarity = "PPM" 
method = "PCC"
normalise.scores = TRUE
if (normalise.scores == TRUE) {
  normalization  <- "norm"
} else {
  normalization  <- ""
}
# clustering for archetyping
min_cluster_similarity <- 0.8
hclust_method <- "complete"
dist_method <- "euclidean"
# archetyping threshold
IC_threshold <- 0.5
len_threshold <- 8
```

Calculate pairwise similarity

```{r eval=FALSE}
# motifs
pwms <- readRDS(file.path(res_dir,"motifs-all.rds"))

# similarity
sim_mat <- compare_motifs(
  motifs = pwms, 
  use.type = similarity, 
  method = method, 
  normalise.scores = normalise.scores, 
  min.position.ic = 0,
  min.mean.ic = 0
)
rownames(sim_mat) <- colnames(sim_mat) <- names(pwms)
saveRDS(sim_mat,file.path(res_dir,sprintf("motifs-similarity-%s-%s%s.rds",similarity,method,normalization)))

```

Cluster and order similarity matrix, then generate archetype motifs.  

Choose the minimum cluster similarity appropriately so that clusters of motifs to archetype contain only similar motifs (e.g. when using a higher value of 0.8, many cluster contain outlier motifs, with lower values these get split).

```{r message=FALSE, eval=FALSE}
# motifs and similarity
pwms <- readRDS(file.path(res_dir,"motifs-all.rds"))
sim_mat <- readRDS(file.path(res_dir,sprintf("motifs-similarity-%s-%s%s.rds",similarity,method,normalization)))

# ordering
reclust_motifs <- TRUE
ord <- rownames(sim_mat)
if (reclust_motifs) {
  hc <- hclust(dist(sim_mat, method = dist_method), method = hclust_method)
  ord <- hc$labels[hc$order]
}
cuts <- seq(200,300,10)
cuts_scores <- sapply(cuts, function(h) {
  ctr <- cutree(hc, k=h)
  cl_scores <- sapply(unique(ctr),function(x) {
    ms <- names(ctr[ctr==x])
    within_cl <- median(sim_mat[ms,ms], na.rm=TRUE)
    between_cl <- median(unlist(sim_mat[!(rownames(sim_mat)%in%ms),ms]), unlist(sim_mat[ms,!(colnames(sim_mat)%in%ms)]), na.rm=TRUE)
    if (is.na(between_cl)) between_cl <- 1
    within_cl/between_cl
  })
  mean(cl_scores, na.rm=TRUE)
})
k <- cuts[which.max(cuts_scores)]
plot(cuts,cuts_scores)
abline(v=k)
ctr <- cutree(hc, k=k)

# archetyping
arch <- mta_merge_archetype(
  sim_mat = sim_mat, 
  motifs = pwms,
  clusters = ctr,
  min_cluster_similarity = min_cluster_similarity,
  recluster = FALSE, 
  block_filter = TRUE,
  bkg = rep(0.25,4), 
  pseudocount = 0.0001, 
  IC_threshold = IC_threshold, 
  len_threshold = len_threshold,
  occupancy_threshold = 1,
  verbose = TRUE
)
# list of 1118 archetypes including 3276 motifs (131 archetype(s) fail filters)
arch <- arch[sapply(arch, function(x) length(x)>0)]
arch_file <- file.path(res_dir,sprintf("motif-archetypes-%s-%s%s-%s-IC%s-%sbp.rds",similarity,method,normalization,min_cluster_similarity,IC_threshold,len_threshold))
saveRDS(arch, arch_file)
```

Annotate archetype motifs (dictionary).

```{r eval=FALSE}
# archetype motifs
arch_file <- file.path(res_dir,"motif-archetypes-PPM-PCCnorm-0.8-IC0.5-8bp.rds")
arch <- readRDS(arch_file)

# cisbp direct and inferred motifs for nematostella assigned to genes
CisBP_ann_file <- file.path("annotation","CisBP_ident_transfered_motifs.tsv")
cisbp_ann <- fread(CisBP_ann_file)
setnames(cisbp_ann,c("Gene_ID","Motif_ID"),c("gene","motif"))
cisbp_tfs <- cisbp_ann[,.(gene,motif)][]
TF_motifs_file <- file.path(res_dir,"CisBP_ident_transfered_genes_to_motifs.tsv")
fwrite(cisbp_tfs, TF_motifs_file, sep="\t")

# cisbp family annotation for all direct TFs
CisBP_family_annotation_file <- file.path("annotation","CisBP_2021_08_11_TF_Information.txt")

# tf annotations
TF_annotation_file <- file.path("annotation","curated_TFh_Nvec_DToL_names.tsv")
TF_family_annotation_file <- file.path("annotation","gene_families_searchinfo.csv")

# mapping between CisBP and our TF family annotations
CisBP_TF_family_mapping_file <- file.path("annotation","CisBP_TF_mapping.tsv")

# make dictionary
dict <- mta_archetype_dictionary(
  arch = arch, 
  TF_annotation_file = TF_annotation_file, 
  TF_motifs_file = TF_motifs_file,
  TF_family_annotation_file = TF_family_annotation_file,
  CisBP_family_annotation_file = CisBP_family_annotation_file,
  CisBP_TF_family_mapping_file = CisBP_TF_family_mapping_file
)

# save dictonary
fwrite(dict, str_replace(arch_file, ".rds$",".dict"), sep="\t", quote=FALSE, col.names = TRUE)

```

```{r fig.width=6, fig.height=4, message=FALSE, warning=FALSE}
arch_file <- file.path(res_dir,"motif-archetypes-PPM-PCCnorm-0.8-IC0.5-8bp.rds")
dict <- fread(str_replace(arch_file, ".rds$",".dict"))
dict_nmot <- dict[,.(archetype_name,archetype_num_motifs)]
gp_nmot <- ggplot(dict_nmot, aes(archetype_num_motifs)) + 
  geom_bar(color="white") +
  scale_x_continuous(expand = expansion(mult=0.01), breaks = c(1,seq(10,100,10))) +
  scale_y_continuous(expand = expansion(mult=c(0,0.01))) +
  theme(panel.grid.major = element_line(size=0.5)) +
  labs(x="number of motifs per archetype", y="number of archetypes")
gp_nmot
```
```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "motifs-archetypes-number.pdf"), width=6, height=4)
gp_nmot
dev.off()
```

Plot archetyping clusters.

```{r message=FALSE, warning=FALSE, eval=FALSE}
# plot archetyping clusters
archetyping_file <- file.path(
  fig_dir,
  basename(file.path(str_replace(arch_file, "\\.rds$", "-archetyping.pdf")))
)
mta_plot_archetype(arch = arch, dict = dict, output_file = archetyping_file)

# plot archetype logos
pdf(file.path(fig_dir, basename(str_replace(arch_file, "\\.rds$", "-archetypes.pdf"))), width=8, height=3)
for (x in seq_along(arch)) {
  message(x)
  motif <- arch[[x]]$ppm_consensus
  motif@name <- dict[archetype_num==paste0("ARCH",x)]$archetype_name[1]
  motif@alphabet <- "DNA"
  tryCatch({
    print(view_motifs(
      motifs = motif,
      relative_entropy = TRUE,
      normalise.scores = FALSE
    ) + labs(title = x))
  }, error=function(e) message(sprintf("Failed to plot ARCH%s\n%s",x,e)))
}
dev.off()
```

Save archetype motifs.

```{r eval=FALSE}
# save motifs
arch <- readRDS(arch_file)
archetypes <-  lapply(arch, function(x) x$ppm_consensus@name)
archetypes_names <- names(arch)
for (x in archetypes_names) {
  arch[[x]]$ppm_consensus@name <- x
}
arch_list <- lapply(arch, function(x) x$ppm_consensus)
saveRDS(arch_list, str_replace(arch_file, ".rds$","-pwms.rds"))

universalmotif::write_homer(
  motifs = arch_list, 
  file = str_replace(arch_file, ".rds$","-pwms.homer"), 
  overwrite = TRUE
)

arch_list <- lapply(arch_list, function(x) {
  x@alphabet <- "DNA"
  x
}) 
universalmotif::write_meme(
  motifs = arch_list, 
  file = str_replace(arch_file, ".rds$","-pwms.meme"), 
  overwrite = TRUE
)

```

Plot heatmap of similarity of all motifs used in archetyping (i.e. motifs after filtering), with archetyping clusters indicated.

```{r eval=FALSE}
require(ComplexHeatmap)

pwms <- readRDS(file.path(res_dir,"motifs-all.rds"))
sim_mat_file <- file.path(res_dir,"motifs-similarity-PPM-PCCnorm.rds")
sim_mat <- readRDS(sim_mat_file)
arch_file <- file.path(res_dir,"motif-archetypes-PPM-PCCnorm-0.8-IC0.5-8bp.rds")
arch <- readRDS(arch_file)
dict <- fread(str_replace(arch_file, ".rds$",".dict"))
names(arch) <- unique(dict$archetype_name)
heatmap_file <- file.path(
  fig_dir,
  str_replace_all(basename(sim_mat_file), c("similarity"="similarity-archetypes", ".rds$"=".pdf"))
)
mta_plot_archetype_heatmap(sim_mat = sim_mat, arch = arch, dict = dict, output_file = heatmap_file, height=14, width=16)
```

How many TFs (do not) have archetypes, and how many archetypes (do not) have a TF?

```{r fig.height=8, fig.width=6, message=FALSE, warning=FALSE}
tf_ann <- fread("annotation/curated_TFh_Nvec_DToL_names.tsv", header = FALSE)
setnames(tf_ann, c("gene","pfam","og"))
dict <- fread(file.path(res_dir,"motif-archetypes-PPM-PCCnorm-0.8-IC0.5-8bp.dict"))

# subset only expressed TFs
tpm <- read.table("RNASEQ_QUANTIFICATION/merged_quantification_transcripts.tsv")
gmx <- apply(tpm, 1, max)
tf_exp <- tf_ann[gene %in% names(gmx[gmx>1])]
nrow(tf_exp)

# subset only expressed TFs
# cdt <- fread("RNASEQ_QUANTIFICATION/raw_counts_rnaseq.tsv")
# cnt <- data.matrix(cdt[,-1])
# rownames(cnt) <- cdt$transcript
# gmx <- apply(cnt, 1, max)
# tf_exp <- tf_ann[gene %in% names(gmx[gmx>10])]
# nrow(tf_exp)

# TFs without an archetype
tfs_dt <- unique(dict[gene!=""][,.(archetype_name,gene)])[,.(number_of_motifs=.N),gene][order(number_of_motifs)]
orp_tfs <- unique(tf_exp[!gene %in% dict$gene]$gene)
gp_tfs <- ggplot(tfs_dt, aes(number_of_motifs)) + 
  geom_bar(color="white") + 
  scale_x_continuous(expand = expansion(mult=0.01), breaks = c(1,seq(10,100,10))) +
  scale_y_continuous(expand = expansion(mult=c(0,0.01))) +
  theme(panel.grid.major = element_line(size=0.5)) +
  labs(x="number of archetype motifs per TF", y="number of TFs", caption = sprintf("%s TFs with motif(s); %s TFs without a motif",nrow(tfs_dt),length(orp_tfs)))

# archetypes without a TF
arc_dt <- unique(dict[gene!=""][,.(archetype_name,gene)])[,.(number_of_genes=.N),archetype_name][order(number_of_genes)]
orp_arc <- unique(dict[!archetype_name %in% arc_dt$archetype_name]$archetype_name)
gp_arc <- ggplot(arc_dt, aes(number_of_genes)) + 
  geom_bar(color="white") + 
  scale_x_continuous(expand = expansion(mult=0.01)) +
  scale_y_continuous(expand = expansion(mult=c(0,0.01))) +
  theme(panel.grid.major = element_line(size=0.5)) +
  labs(x="number of TFs per archetype motif", y="number of archetype motifs", caption = sprintf("%s motifs with gene(s); %s motifs without a gene",nrow(arc_dt),length(orp_arc)))


gp_tfs / gp_arc

```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "motifs-archetypes-tf-mapping.pdf"), width=6, height=8)
gp_tfs / gp_arc
dev.off()
```

Missing TFs and motifies classified in TF families

```{r fig.height=6, fig.width=6, message=FALSE, warning=FALSE, echo=FALSE}
TF_family_annotation_file <- file.path("annotation","gene_families_searchinfo.csv")
tf_fams <- fread(TF_family_annotation_file)

# missing TFs
orp_tfs_dt <- tf_ann[gene %in% orp_tfs]
# get family info from gene og
orp_tfs_dt[og!="",tf_family:=str_remove(og,"\\.(?<=\\.).+")]  
orp_tfs_dt[, tf_family:=str_replace_all(tf_family, "AP2", "AP-2")]
# summarize
orp_tfs_dtn <- orp_tfs_dt[,.N,tf_family][,prop:=N/sum(N)][order(-N)]
orp_tfs_dtn_plot <- copy(orp_tfs_dtn)
orp_tfs_dtn_plot[N<5, ':='(tf_family="other",N=sum(N),prop=sum(prop))]
orp_tfs_dtn_plot <- unique(orp_tfs_dtn_plot)
orp_tfs_dtn_plot[,tf_family:=factor(tf_family, levels=orp_tfs_dtn_plot$tf_family)]

# missing motifs
orp_arc_dt <- dict[archetype_name %in% orp_arc]
# get family info from archetype name
orp_arc_dt[tf_family=="",tf_family:=str_extract(archetype_name,paste(tf_fams[[1]],collapse="|"))]
# get family info from motifs names
orp_arc_na <- orp_arc_dt[is.na(tf_family),][
  ,tf_family:=str_extract(motif,paste(tf_fams[[1]],collapse="|"))][
    ,.(archetype,tf_family)][
      !is.na(tf_family)]
orp_arc_vc <- structure(orp_arc_na$tf_family, names=orp_arc_na$archetype)
orp_arc_dt[archetype %in% names(orp_arc_vc), tf_family:=orp_arc_vc[archetype]]
# guess family info from archetype names
grep_list2 <- list(
  "fox" = "Forkhead",
  "hox" = "Homeodomains",
  "sox" = "HMGbox_Sox",
  "runx|runt" = "Runt_Runx",
  "mads|srf" = "MADS-box_SRF",
  "Myb_DNA-bind" = "Myb"
)
nms <- unlist(strsplit(tf_fams[[2]],","))
fms <- unname(unlist(lapply(1:nrow(tf_fams), function(i) rep(tf_fams[i,1], length(strsplit(as.character(tf_fams[i,2]),",")[[1]])))))
grep_list1 <- fms; names(grep_list1) <- nms
grep_list <- c(grep_list1, grep_list2)
for (gp in names(grep_list)) {
  orp_arc_dt[is.na(tf_family) & grepl(gp, archetype, ignore.case = TRUE), tf_family:=grep_list[[gp]]]
}
orp_arc_dt[, tf_family:=str_replace_all(tf_family, "AP2", "AP-2")]
# summarize
orp_arc_dt[is.na(tf_family), tf_family:="unknown"]
orp_arc_dtn <- orp_arc_dt[,.N,tf_family][,prop:=N/sum(N)][order(-N)]
orp_arc_dtn[,tf_family:=factor(tf_family, levels=orp_arc_dtn$tf_family)]

# colors
tf_fams <- unique(sort(c(tf_fams[[1]], unique(orp_tfs_dt$tf_family))))
tf_fams <- tf_fams[tf_fams %in% c(as.character(orp_tfs_dtn$tf_family), as.character(orp_arc_dt$tf_family))]
tf_fams <- str_replace_all(tf_fams, "AP2", "AP-2")
tf_fams_cols <- structure(
  c(colorRampPalette(RColorBrewer::brewer.pal(8,'Paired'))(length(tf_fams)), "khaki", "grey"),
  names = c(tf_fams, "other", "unknown")
)

# plots
gp_orp_tfs <- ggplot(orp_tfs_dtn_plot, aes("", N, fill=tf_family)) +
  geom_bar(stat="identity", width=1, color="black") +
  coord_polar("y", start=0) +
  scale_fill_manual(values = tf_fams_cols, limits = force) +
  geom_text(
    aes(label = ifelse(
      prop<0.02, 
      "", 
      sprintf("%s (%s)",tf_family,scales::percent(prop,accuracy=1))
    ), x=1.4),
    position = position_stack(vjust=0.5),
    color = "black"
  ) +
  labs(title = "orphan TFs") +
  theme_void() +
  theme(legend.position = "none")

gp_orp_arc <- ggplot(orp_arc_dtn, aes("", N, fill=tf_family)) +
  geom_bar(stat="identity", width=1, color="black") +
  coord_polar("y", start=0) +
  scale_fill_manual(values = tf_fams_cols, limits = force) +
  geom_text(
    aes(label = ifelse(
      prop<0.02, 
      "", 
      sprintf("%s (%s)",tf_family,scales::percent(prop,accuracy=1))
    ), x=1),
    position = position_stack(vjust=0.5),
    color = "black"
  ) +
  labs(title = "orphan motif archetypes") +
  theme_void() +
  theme(legend.position = "none")

# plot
gp_orp_tfs + gp_orp_arc 
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "motifs-archetypes-tf-orphans.pdf"), width=8, height=4)
gp_orp_tfs + gp_orp_arc 
dev.off()
```

```{r fig.height=10, fig.width=5}
orp_dtn <- rbindlist(list("TFs"=orp_tfs_dtn, "archetypes"=orp_arc_dtn), idcol = "variable")
orp_dtn <- orp_dtn[tf_family!="unknown"]

gp_orp <- ggplot(orp_dtn, aes(tf_family)) + 
  geom_bar(
    data = subset(orp_dtn, variable == "TFs"), 
    aes(y = N, fill = tf_family), 
    stat = "identity", position = "dodge", color = "black") +
  geom_bar(
    data = subset(orp_dtn, variable == "archetypes"), 
    aes(y = -N, fill = tf_family), 
    stat = "identity", position = "dodge", color = "black") + 
  coord_flip() +
  scale_fill_manual(values = tf_fams_cols, limits = force) +
  scale_y_continuous(limits=c(-50,NA)) +
  # geom_hline(yintercept = 0,colour = "black") +
  theme(
    legend.position = "none", 
    panel.grid.major.x = element_line(size=0.5)) +
  labs(y="number of motifs or TFs", x="TF family")
gp_orp
```

```{r include=FALSE, eval=TRUE}
pdf(file.path(fig_dir, "motifs-archetypes-tf-orphans-counts.pdf"), width=6, height=12)
gp_orp
dev.off()
```

## Footprinting

Merge replicates per condition

```{bash eval=FALSE}
bam_dir="ATACSEQ/nucleosome_free_regions/bam/"
nth=18

for line in Fox Elav Ncol
do
  for cond in pos neg
  do
    name=${line}_${cond}
    echo ${name}
    bams=$( echo ${bam_dir}/${name}*bam )
    samtools merge -@ ${nth} ${bam_dir}/${name}.ncfree.bam ${bams}
    samtools sort -@ ${nth} -o ${bam_dir}/${name}.ncfree.sorted.bam ${bam_dir}/${name}.ncfree.bam
    rm ${bam_dir}/${name}.ncfree.bam
    samtools index -@ ${nth} ${bam_dir}/${name}.ncfree.sorted.bam
  done
done
```

Footprint score calculation for consensus peaks

```{bash eval=FALSE}
conda activate TOBIAS_ENV
bam_dir="ATACSEQ/nucleosome_free_regions/bam/"
out_dir="ATACSEQ/nucleosome_free_regions/footprint/"
mkdir ${out_dir}
peaks="ATACSEQ/nucleosome_free_regions/consensus_peaks/consensusSeekeR-peaks.bed"
genome="genome/Nvec_vc1.1_gDNA.fasta"
nth=12

for line in Fox Elav Ncol
do
  for cond in pos neg
  do
    name=${line}_${cond}
    
    echo $(date) "- Starting ATACorrect for" ${name}
    TOBIAS ATACorrect \
      --bam ${bam_dir}/${name}.ncfree.sorted.bam \
      --genome ${genome} \
      --peaks ${peaks} \
      --prefix ${name} \
      --outdir ${out_dir}/ATACorrect \
      --cores ${nth}
    
    echo $(date) "- Starting FootprintScores"
    TOBIAS FootprintScores \
      --signal ${out_dir}/ATACorrect/${name}_corrected.bw \
      --regions ${peaks} \
      --fp-min 10 --fp-max 50 \
      --output ${out_dir}/${name}_footprints.bw \
      --cores ${nth}
    
  done
done

```
